{
  "hash": "982c24862cebba1317218c4ea4add535",
  "result": {
    "engine": "julia",
    "markdown": "---\ntitle: \"Lab 2 Solutions\"\nformat:\n    html:        \n        warning: true\n        error: true\n    ipynb:\n        warning: true\n        error: true\n        code-annotation: below\n    pdf:\n        include-in-header: \n           text: |\n            \\usepackage{fvextra}\n            \\DefineVerbatimEnvironment{Highlighting}{Verbatim}{breaklines,commandchars=\\\\\\{\\}}\n            \\DefineVerbatimEnvironment{OutputCode}{Verbatim}{breaklines,commandchars=\\\\\\{\\}}\nengine: julia\nformat-links: [pdf, ipynb]\n---\n\n\n\n\n\n::: {.content-visible when-format=\"ipynb\"}\n::: {.cell .markdown}\n**Name**:\n\n**ID**:\n:::\n:::\n\n::: {.callout-important icon=false}\n### Due Date\n\nWednesday, 9/25/24, 9:00pm\n:::\n\n::: {.content-visible when-format=\"html\"}\n\n:::{.callout-caution}\n\nIf you are enrolled in the course, make sure that you use the GitHub Classroom link provided in Ed Discussion, or you may not be able to get help if you run into problems.\n\nOtherwise, you can [find the Github repository here]({{< var github_org.repo >}}/lab02).\n\n:::\n\n:::\n\n## Setup\n\nThe following code should go at the top of most Julia scripts; it will load the local package environment and install any needed packages. You will see this often and shouldn't need to touch it.\n\n\n\n\n\n::: {.cell execution_count=1}\n``` {.julia .cell-code}\nimport Pkg\nPkg.activate(\".\")\nPkg.instantiate()\n```\n:::\n\n\n\n::: {.cell execution_count=1}\n``` {.julia .cell-code}\nusing Random # random number generation\nusing Distributions # probability distributions and interface\nusing Statistics # basic statistical functions, including mean\nusing Plots # plotting\n```\n:::\n\n\n\n\n\n\n\n## Exercise (3 Points)\n\nFirst, let's write a function which compares our bid to (random) showcase value and returns the reward. The only slight complication is calculating the probability of winning if we don't automatically win both showcases and don't overbid. Our assumption is that this is linear, with a win probability of zero when we bid \\$0 and a win probability of one if we bid exactly. So, using the equation of a line between these two points, if our bid is $b$ and the true value is $v$, the probability becomes\n\n$$\n\\mathbb{P}(v - b) = 1 - \\frac{v - b}{v}\n$$\n\nand the expected value of our winnings in this case is $\\mathbb{P}(v - b) \\times v = b$.\n\n\n\n\n\n::: {.cell execution_count=1}\n``` {.julia .cell-code}\nfunction showcase_play(value; bid=35_000) # <1>\n    if bid > value # overbird, win nothing\n        return 0\n    elseif value - bid < 250 # win both showcases\n        return 2 * value\n    else\n        win_prob = (1 + (bid - value) / value)\n        return bid\n    end\nend\n```\n\n::: {.cell-output .cell-output-display execution_count=1}\n```\nshowcase_play (generic function with 1 method)\n```\n:::\n:::\n\n\n\n\n\n\n1. The semi-colon and assigned value makes `bid` an optional parameter: if we don't explicitly pass it, it will take on that assumed value, but we can change it by calling `showcase_play(value; bid=x)`.\n\nNow we can conduct our Monte Carlo experiment. Let's write another function which takes in a vector of showcase values and computes the running average of winnings.\n\n\n\n\n\n::: {.cell execution_count=1}\n``` {.julia .cell-code}\nfunction showcase_mc(values)\n    exp_winnings = zeros(length(values)) # <1>\n    for (i, value) in pairs(values) # <2>\n        if i == 1\n            exp_winnings[i] = showcase_play(value)\n        else\n            exp_winnings[i] = ((i - 1) * exp_winnings[i - 1] + showcase_play(value)) / i # <3>\n        end\n    end\n    return exp_winnings\nend\n```\n\n::: {.cell-output .cell-output-display execution_count=1}\n```\nshowcase_mc (generic function with 1 method)\n```\n:::\n:::\n\n\n\n\n\n\n1. This initializes the storage for a vector which will store the running average for every iteration.\n2. `pairs(v)` returns an iterator over tuples containing both the index and the value of each element of `v`. This is safer than `for i = 1:length(v)` for a larger variety of data structures and avoids having to explicitly look up `value = v[i]`. If we didn't need the index, we could have used `for value in values`, but we want to be to write to the right index in `exp_winnings`.\n3. We could just compute the average each time over the entire chunk of the vector, but this is a little faster for cases where the evaluation is more expensive as we avoid re-computing.\n\nNow if we draw 20,000 samples (this is large for illustrative purposes), we can compute how the Monte Carlo estimates change (visualized in @fig-mc).\n\n\n\n\n\n::: {.cell execution_count=1}\n``` {.julia .cell-code}\nRandom.seed!(1) # <1>\nshowcase_dist = truncated(Normal(31000, 4500), lower=5000, upper=42000)\nshowcase_samples = rand(showcase_dist, 20_000)\n\nwinnings_mc = showcase_mc(showcase_samples)\nplot(winnings_mc, xlabel=\"Monte Carlo Iteration\", ylabel=\"Expected Winnings (\\$)\", label=false)\n```\n\n::: {.cell-output .cell-output-display execution_count=1}\n![Monte Carlo estimates of expected winnings for a $35,000 bid over 20,000 showcase samples.](lab02_files/figure-pdf/fig-mc-output-1.svg){#fig-mc fig-pos='H'}\n:::\n:::\n\n\n\n\n\n\n1. Setting a seed ensures we'll get the same samples regardless of when we re-run this notebook.\n\nBased on this, the estimated value is \\$6999.\n\nHow could we decide how many samples to use? Later, we'll see in class how we can compute a more formal analysis of the error in the Monte Carlo estimate, but for the purposes of this lab, we would like to ensure that the estimate has stabilized. If we had only used the first 1,000 samples, we would see @fig-mc-small.\n\n\n\n\n\n::: {.cell execution_count=1}\n``` {.julia .cell-code}\nplot(winnings_mc[1:1000], xlabel=\"Monte Carlo Iteration\", ylabel=\"Expected Winnings (\\$)\", label=false)\n```\n\n::: {.cell-output .cell-output-display execution_count=1}\n![Monte Carlo estimates of expected winnings for a $35,000 bid over 1,000 showcase samples.](lab02_files/figure-pdf/fig-mc-small-output-1.svg){#fig-mc-small fig-pos='H'}\n:::\n:::\n\n\n\n\n\n\n\nWe can see that there is still some variability as of the last iteration, so we might want to use more samples.^[Note that this variability might be ok depending on the outcomes of the error analysis and our desire for precision, but more on that soon.] If we use 5,000 samples, we can see the results in @fig-mc-more.\n\n\n\n\n\n::: {.cell execution_count=1}\n``` {.julia .cell-code}\nplot(winnings_mc[1:5000], xlabel=\"Monte Carlo Iteration\", ylabel=\"Expected Winnings (\\$)\", label=false)\n```\n\n::: {.cell-output .cell-output-display execution_count=1}\n![Monte Carlo estimates of expected winnings for a $35,000 bid over 5,000 showcase samples.](lab02_files/figure-pdf/fig-mc-more-output-1.svg){#fig-mc-more fig-pos='H'}\n:::\n:::\n\n\n\n\n\n\n\nThis looks much better! So we could have used 5,000, but it will turn out that more will always be \"safer\".\n\n::: {.cell .markdown}\n\n## References\n\nPut any consulted sources here, including classmates you worked with/who helped you.\n:::\n\n",
    "supporting": [
      "lab02_files/figure-pdf"
    ],
    "filters": []
  }
}
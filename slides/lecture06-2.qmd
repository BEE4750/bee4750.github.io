---
title: "Linear Programming"
subtitle: "Lecture 16"
author: "Vivek Srikrishnan"
course: "BEE 4750"
institution: "Cornell University"
date: "September 27, 2023"
format:
    revealjs:
        slide-number: c/t
        show-slide-number: all
        center-title-slide: true
        width: 1280
        height: 720
        transition: none
        toc: true
        toc-depth: 1
        toc-title: "Overview"
        history: false
        link-external-newwindow: true
        theme: ../sass/slides.scss
        footer: "[BEE 4750, Environmental Systems Analysis](https://viveks.me/environmental-systems-analysis)"
        template-partials:
            - title-slide.html
        menu:
            numbers: true
        html-math-method: mathjax
        include-in-header: mathjax-config.html
        date-format: long
        highlight-style: tango
        code-line-numbers: false

execute:
    freeze: auto
---

```{julia}
#| echo: false
#| output: false

import Pkg
Pkg.activate(".")
Pkg.instantiate()
```

```{julia}
#| echo: false
#| output: false

using Measures
using Random
using Distributions
using Plots
using StatsPlots
using LaTeXStrings

Random.seed!(1)
```

# Review and Questions

## Last Class

- Optimization for solving decision problems.
- Used graphical method to identify solution for low (2-d) decision problem.
- Discussed trial and error and search algorithms.
- For unconstrained problems, gradient-based methods can get "stuck" at local optima.
- Evolutionary algorithms can require many iterations and evaluations.

## Questions?

{{< include _poll-prompt.qmd >}}

# Constrained Optimization

## Unconstrained Optimization

:::: {.columns}
::: {.column width=50%}

![Function with Multiple Minima](images/multiple-optima.svg)
:::

::: {.column width=50%}

Without constraints, our goal is to find extrema of the function.

Can do this using the structure of the objective (gradient) or through stochastic search (Monte Carlo).
:::
::::

## Constrained Optimization

:::: {.columns}
::: {.column width=50%}

![Function with Multiple Minima and a Constraint](images/multiple-optima-constrained.svg)
:::

::: {.column width=50%}
Now, notice the effect of a constraint!


For a constrained problem, we also have to look along the constraint to see if that creates a solution.
:::

::::

## Lagrange Multipliers

We can solve some constrained problems using Lagrange Multipliers!


Recall (maybe) that the Lagrange Multipliers method requires *equality* constraints. But we can easily create those with "dummy" variables.

## Using Equality Constraints

:::: {.columns}
::: {.column width=50%}

**Original Problem**


$$
\begin{aligned}
& \min &&f(x_1, x_2) \notag \\\\
& \text{subject to:} && x_1 \geq A \notag \\
& && x_2 \leq B \notag
\end{aligned}
$$
:::

::: {.column width=50%}

**With Dummy Variables**


$$
\begin{aligned}
& \min &&f(x_1, x_2) \notag \\\\
& \text{subject to:} && x_1 - S_1^2 = A \notag \\
& && x_2 + S_2^2 = B \notag
\end{aligned}
$$
:::
::::

## Using Lagrange Multipliers

Then the Lagrangian function becomes:


$$
H(\mathbf{x}, S_1, S_2, \lambda_1, \lambda_2) = f(\mathbf{x}) - \lambda_1(x_1 - S_1^2 - A) - \lambda_2(x_2 + S_2^2 - B)
$$


where $\lambda_1$, $\lambda_2$ are penalties for violating the constraints.


The $\lambda_i$ are the eponymous *Lagrange multipliers*.

## Using Lagrange Multipliers


Next step: locate possible optima where the partial derivatives of the Lagrangian are zero.

$$\frac{\partial H(\cdot)}{\partial \cdot} = 0$$

This is actually many equations, even though our original problem was low-dimensional, and can be slow to solve.

## Using Lagrange Multiplers

Despite these challenges, Lagrange Multiplers are at the core of many advanced search algorithms.

# Linear Programming

## What is Linear Programming?

Linear programming refers to optimization for **linear models**.

As we will see over the next few weeks, linear models are:

- relatively simple (which lets us solve and analyze them "easily");
- surprisingly applicable to many contexts!

## Linear Functions

Recall that a function $f(x_1, \ldots, x_n)$ is **linear** if
$$f(x_1, \ldots, x_n) = a_1x_1 + a_2x_2 + \ldots + a_n x_n.$$

::: {.fragment .fade-in}
The key is that linear models are very simple geometrically:

- Define hyperplanes;
- Constant derivatives/gradients.
:::

## Linear Programs

A **linear program** (**LP**), or a *linear optimization model*, has the following characteristics:

- **Linearity**: The objective function and constraints are all linear;
- **Divisibility**: The decision variables are continuous (they can be fractional levels);
- **Certainty**: The problem is deterministic.

## Linearization

:::: {.columns}
::: {.column width=50%}
Linear models are useful because we can *linearize* nonlinear functions.

When we linearize components of an LP, this is called the *linear relaxation* of the original problem.
:::
::: {.column width=50%}
```{julia}
E = 0:0.01:1
p = plot(E, E.^2, legend=false, grid=false, xlabel="Efficiency", ylabel="Cost", color=:black, yticks=false, xlims=(0, 1), ylims=(0, 1), left_margin=8mm, linewidth=3, tickfontsize=16, guidefontsize=16)
xticks!([0.65, 0.95])
xlims!((0, 1.05))
scatter!([0.65, 0.95], [0.65, 0.95].^2, markersize=10, color=:blue)
plot!(E, 1.6 .* E  .- 0.6175, color=:blue, linestyle=:dash, linewidth=3)
plot!(size=(600, 600))
```
:::
::::

## Linearization

:::: {.columns}
::: {.column width=50%}
Note that the linearization is often quite sensitive to the points that are used to find the slope.

So this is best done when you have a rough idea of the variable range of interest.
:::
::: {.column width=50%}
```{julia}
scatter!([0.32, 0.98], [0.32, 0.98].^2, markersize=10, color=:red)
plot!(p, E, 1.3 .* E  .- 0.31, color=:red, linestyle=:dot, linewidth=3)
```
:::
::::

## Why Is Solving LPs Straightforward?

:::: {.columns}
::: {.column width=50%}
```{julia, lp-sketch}
x = 2:0.1:11
f1(x) = 4.5 .* x
f2(x) = -x .+ 16
f3(x) = -1.5 .* x .+ 12
f4(x) = 0.5 .* x

p = plot(x, max.(f3(x), f4(x)), fillrange=min.(f1(x), f2(x)), color=:lightblue, grid=true, legend=false, xlabel=L"x", ylabel=L"y", xlims=(-2, 20), framestyle=:origin, ylims=(-2, 20), minorticks=5, tickfontsize=16, guidefontsize=16, right_margin=5mm)
plot!(-2:0.1:20, f1.(-2:0.1:20), color=:green, linewidth=3)
plot!(-2:0.1:20, f2.(-2:0.1:20), color=:red, linewidth=3)
plot!(-2:0.1:20, f3.(-2:0.1:20), color=:brown, linewidth=3)
plot!(-2:0.1:20, f4.(-2:0.1:20), color=:purple, linewidth=3)
plot!(size=(600, 600))
```
:::
::: {.column width=50%}
All solutions must exist on the boundary of the feasible region (which must be a *polytope*).
:::
::::

## Why Is Solving LPs Straightforward?

:::: {.columns}
::: {.column width=50%}
```{julia}
p
```
:::
::: {.column width=50%}
More specifically:

::: {.incremental}
- an optimum solution must occur at the intersection of constraints;
- can focus on finding and analyzing the corners. 
:::
:::
::::

## Why Is Solving LPs Straightforward?

:::: {.columns}
::: {.column width=50%}
```{julia}
p
```
:::
::: {.column width=50%}
This is the basis of all *simplex* methods for solving LPs.

These methods go back to George Dantzig in the 1940s and are still widely used today.
:::
::::

## Example: Solving an LP

:::: {.columns}
::: {.column width=50%}
$$\begin{alignedat}{3}
& \max_{x_1, x_2} &  230x_1 + 120x_2 &  \\\\
& \text{subject to:} & &\\
& & 0.9x_1 + 0.5x_2 &\leq 600 \\
& & x_1 + x_2 &\leq 1000 \\
& & x_1, x_2 &\geq 0
\end{alignedat}$$
:::
::: {.column width=50%}
```{julia}
x1 = 0:1200
x2 = 0:1400
f1(x) = (600 .- 0.9 .* x) ./ 0.5
f2(x) = 1000 .- x

p = plot(0:667, min.(f1(0:667), f2(0:667)), fillrange=0, color=:lightblue, grid=true, label="Feasible Region", xlabel=L"x_1", ylabel=L"x_2", xlims=(-50, 1200), ylims=(-50, 1400), framestyle=:origin, minorticks=4, right_margin=4mm, left_margin=4mm, legendfontsize=14, tickfontsize=16, guidefontsize=16)
plot!(0:667, f1.(0:667), color=:brown, linewidth=3, label=false)
plot!(0:1000, f2.(0:1000), color=:red, linewidth=3, label=false)
annotate!(400, 1100, text(L"0.9x_1 + 0.5x_2 = 600", color=:purple, pointsize=18))
annotate!(1000, 300, text(L"x_1 + x_2 = 1000", color=:red, pointsize=18))
plot!(size=(600, 600))
```
:::
::::

## Example: Solving an LP

:::: {.columns}
::: {.column width=50%}
$$\begin{alignedat}{3}
& \max_{x_1, x_2} &  230x_1 + 120x_2 &  \\\\
& \text{subject to:} & &\\
& & 0.9x_1 + 0.5x_2 &\leq 600 \\
& & x_1 + x_2 &\leq 1000 \\
& & x_1, x_2 &\geq 0
\end{alignedat}$$
:::
::: {.column width=50%}
```{julia}
Z(x1,x2) = 230 * x1 + 120 * x2
contour!(0:660,0:1000,(x1,x2)->Z(x1,x2), levels=5, c=:devon, linewidth=2, colorbar = false, clabels = true) 
```
:::
::::

## Examining Corner Points

:::: {.columns}
::: {.column width=50%}
Corner $(x_1, x_2)$ | Objective
:------------: | -------------:
$(0,0)$      | $0$
$(0, 1000)$ | $12000$
$(667, 0)$  | $153410$
$(250, 750)$ | $147500$
:::
::: {.column width=50%}

```{julia}
scatter!(p, [0, 0, 667, 250], [0, 1000, 0, 750], markersize=10, z=2, label="Corner Point", markercolor=:orange)
```
:::
::::

## Solving an LP

Manually checking the corner points is all well and good for this simple example, but does it scale well?

::: {.fragment .fade-in}
LP solvers (often based off the simplex method) automate this process.
:::

# Key Takeaways

## Key Takeaways

- Trial and error: not a great approach!
- Search algorithms: better!
- Linear Programs: straightforward to solve!
- For an LP, an optimum must occur at a corner of the feasible polytope.

# Upcoming Schedule

## Next Classes

**Friday**: Example of formulating and solving an LP

**Monday**: Lab on solving LPs in Julia with `JuMP.jl`